---
author: Blake Miller
output: html_document
---

## Wordscores
#supervisor is not scaling - either belong to class or not

The following code replicates the UK manifestos scaling example from LBG 2003.

```{r}
# loading data
library(quanteda)
data(data_corpus_ukmanifestos, package = "quanteda.corpora")
# cleaning dataset
ukCorpus <- corpus_subset(data_corpus_ukmanifestos, Year %in% c(1992, 1997) & Party %in% c("Con", "Lab", "LD"))
# sep="_"  - changes docname -, .  
docnames(ukCorpus) <- paste(docvars(ukCorpus, "Party"), docvars(ukCorpus, "Year"), sep="_")
docnames(ukCorpus)
docvars(ukCorpus)

# creating DFM
ukDfm <- dfm(ukCorpus)
summary(ukCorpus)

# fitting wordscores (3 NA spots- 3 virgins texts we do not know anything about but want to score)
# 3values for 1992, 1997
ws <- textmodel_wordscores(ukDfm, c(17.21, 5.35, 8.21, rep(NA, 3)))
?textmodel_wordscores

# checking a few individual wordscores
#law-abidin - right wing party, school and other two - fall into the other side(left political party)
#coef-gice us the score
coef(ws)[c("law-abiding", "schools", "unemployment", "social")]

# Now trying to predict the scores for all the manifestos
# we have words that are used frequently overlapping acorss the document - reason why the score is different from the coef(ws), thus need rescaling
predict(ws)
# almost but not exactly!
(pred <- predict(ws, newdata = ukDfm[4:6, ], rescaling = "lbg"))

# with smoothing
wsSm <- textmodel_wordscores(ukDfm, c(17.21, 5.35, 8.21, rep(NA, 3)), smooth = 1)
predsm <- predict(wsSm, newdata = ukDfm[4:6,], rescaling = "lbg")
predsm
# in this case it is not doing much - correlation is 0.99
cor(pred, predsm)

```

### Wordscores applied to Twitter data

Let's check another example of wordscores. Here we have tweets from a random sample of 100 Members of the U.S. Congress, as well as their ideal points based on roll-call votes. Can we replicate the ideal points only using the text of their tweets?

First, let's create a corpus and DFM objects

```{r}
cong <- read.csv("data/congress-tweets.csv", stringsAsFactors=F)
# create corpus object
ccorpus <- corpus(cong$text)
docnames(ccorpus) <- cong$screen_name
docvars(ccorpus)
# create DFM
cdfm <- dfm(ccorpus, remove_punct=TRUE, remove=c(stopwords("english"), "t.co", "https", "rt", "amp", "http", "t.c", "can"))
# trimming rare terms - removing noise words 
cdfm <- dfm_trim(cdfm, min_docfreq = 2)
```

Now we can run wordscores on this DFM. To begin with, we choose as reference texts all the documents, simply so that we can look at the individual word scores:

```{r}
# running wordscores
ws <- textmodel_wordscores(cdfm, cong$idealPoint, smooth=.5)
ws
# let's look at the most discriminant words - words that are informative and not informatice
sw <- sort(coef(ws))
#most leaning left words ( #climatechange )
head(sw, n=20)
#more right leaning wordscores (politicians, #jobs)
tail(sw, n=20)
```

Now let's do a more typical example of Wordscores by selecting 20 of the Members of Congress as reference texts and trying to predict the ideal point for the other 80.

```{r}
set.seed(123)
#randomly sample 20 percent of the document 
test <- sample(1:nrow(cong), floor(.20 * nrow(cong)))
# extracting ideal points and replacing them with missing values - all of these will serve as virgin texts 
refpoints <- cong$idealPoint
refpoints[test] <- NA
# running wordscores
ws <- textmodel_wordscores(cdfm, refpoints, smooth=.5)
# predicted values
preds <- predict(ws, rescaling="lbg")
# and let's compare with the actual ideal point estimated 
plot(preds[test], cong$idealPoint[test],
     xlab="Wordscores estimates", 
     ylab="Ideal points from roll-call votes",
     col=ifelse(cong$party[test]=="R", "red", "blue"))
#we got pretty high correlation - analyse the performance of wordscore (similar to machine learning)
cor(preds[test], cong$idealPoint[test])
```

